import branca
import calmap
from datetime import datetime, timedelta, date
from dotenv import load_dotenv
import folium
import geopandas as gpd
import os
import pandas as pd
from PIL import Image
import requests
import streamlit as st
import streamlit.components.v1 as components
from streamlit_folium import st_folium


# ---Environment---
load_dotenv(verbose=True, dotenv_path='.env')
API_KEY = os.environ.get("API_KEY") # Or write your API KEY directly
today = date.today()
yesterday = today - timedelta(days=1)
start_date = date(2022, 12, 1) # Put the date you started tracking
year = today.year
st.set_page_config(page_title="ç§ã®æœæ´»è¨˜éŒ²")


# ---Get Tracking Data---
params = {
    "start_date": start_date,
    "end_date": today
}

data = requests.get('https://api.track.toggl.com/api/v9/me/time_entries',auth=(API_KEY, "api_token"), params=params)


# ---Choose which year to see---
st.title("æœæ´»è¨˜éŒ²")
year_radio = st.radio("", ('ä»Šå¹´', '1å¹´å‰', '2å¹´å‰'), horizontal=True)

if year_radio == '2å¹´å‰':
    year -= 2
elif year_radio == '1å¹´å‰':
    year -= 1
else:
    pass

components.html(
    """
        <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" 
        data-text="Check my cool Streamlit Web-AppğŸˆ" 
        data-url="https://takahiro910-morning-main-knc7b8.streamlit.app/"
        data-show-count="false">
        data-size="Large" 
        data-hashtags="streamlit,python"
        Tweet
        </a>
        <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
    """
)

# ---Data Processing---
df = pd.DataFrame.from_records(data.json())
df = df.dropna(subset=["stop"])

df["start"] = pd.to_datetime(df["start"])
df["stop"] = pd.to_datetime(df["stop"])
df["start"] = df["start"] + timedelta(hours=9) # Adjust time difference
df["year"] = df["start"].dt.year
df["date"] = df["start"].astype(str).str[:10]
df["date"] = pd.to_datetime(df["date"])

df_year = df[(datetime(year, 1, 1) <= df["date"]) & (df["date"] <= datetime(year, 12, 31))]
df_group = df_year.groupby(["date", "project_id"], as_index=False).sum()


# Create with your tracking name and id. Here's my example.
training = df_group[df_group["project_id"] == 187670676.0][["date", "duration"]].rename(columns={"duration":"training"})
self_study = df_group[df_group["project_id"] == 187670689.0][["date", "duration"]].rename(columns={"duration":"self_study"})
english = df_group[df_group["project_id"] == 187670686.0][["date", "duration"]].rename(columns={"duration":"english"})
books = df_group[df_group["project_id"] == 187670687.0][["date", "duration"]].rename(columns={"duration":"books"})

data_total = pd.DataFrame()
data_total["date"] = pd.date_range(datetime(year, 1, 1), datetime(year, 12, 31))
data_total = pd.merge(data_total, training, on="date", how="left")
data_total = pd.merge(data_total, self_study, on="date", how="left")
data_total = pd.merge(data_total, english, on="date", how="left")
data_total = pd.merge(data_total, books, on="date", how="left")
data_total = data_total.set_index("date") # To use calmap, set date into index.


# ---Output---
st.markdown("## ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°")
st.write(calmap.yearplot(data_total["training"], year=year, linewidth=0.1, cmap="Greens").figure)

st.markdown("## èª­æ›¸ãƒ»ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ–ãƒƒã‚¯")
st.write(calmap.yearplot(data_total["books"], year=year, linewidth=0.1, cmap="Greens").figure)

st.markdown("## è‹±èªå­¦ç¿’")
st.write(calmap.yearplot(data_total["english"], year=year, linewidth=0.1, cmap="Greens").figure)

st.markdown("## ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒ»ãã®ä»–")
st.write(calmap.yearplot(data_total["self_study"], year=year, linewidth=0.1, cmap="Greens").figure)


# ---Extra; My profile in sidebar---
with st.sidebar:
    img = Image.open("icon.png")
    st.image(img, caption="ä½œï¼šStable Diffusion", use_column_width=True)
    st.markdown("## ä¸»ãªç”Ÿæ¯åœ°")
    st.markdown("[Twitter](https://twitter.com/uwasanoaitsu910)", unsafe_allow_html=True)
    
    st.markdown("## æœ¬æ£š")
    st.markdown("[ãƒ–ã‚¯ãƒ­ã‚°](https://booklog.jp/users/86fd751fa08e1d1a)", unsafe_allow_html=True)
    expander = st.expander("ãŠã™ã™ã‚æœ¬10å†Šï¼ˆæ„è­˜é«˜ã‚ï¼‰")
    expander.markdown("[å¤šæ§˜æ€§ã®ç§‘å­¦ ç”»ä¸€çš„ã§å‡‹è½ã™ã‚‹çµ„ç¹”ã€è¤‡æ•°ã®è¦–ç‚¹ã§å•é¡Œã‚’è§£æ±ºã™ã‚‹çµ„ç¹”](https://amzn.to/3XGxCnG)")
    expander.markdown("[çŸ¥ã£ã¦ã‚‹ã¤ã‚‚ã‚Š ç„¡çŸ¥ã®ç§‘å­¦](https://amzn.to/3iVCExW)")
    expander.markdown("[å¤±æ•—ã®ç§‘å­¦ å¤±æ•—ã‹ã‚‰å­¦ç¿’ã™ã‚‹çµ„ç¹”ã€å­¦ç¿’å‡ºæ¥ãªã„çµ„ç¹”](https://amzn.to/3QZpZqC)")
    expander.markdown("[ä»£è¡¨çš„æ—¥æœ¬äºº](https://amzn.to/3HiHChQ)")
    expander.markdown("[HIGH OUTPUT MANAGEMENT](https://amzn.to/3iYSKa3)")
    expander.markdown("[PRINCIPLES äººç”Ÿã¨ä»•äº‹ã®åŸå‰‡](https://amzn.to/3GRcdBA)")
    expander.markdown("[ãƒªã‚¹ã‚¯ã‚’å–ã‚‰ãªã„ãƒªã‚¹ã‚¯](https://amzn.to/3GXE8jj)")
    expander.markdown("[äººæœ›ãŒé›†ã¾ã‚‹äººã®è€ƒãˆæ–¹](https://amzn.to/3J6pRn8)")
    expander.markdown("[6ãƒŸãƒ‹ãƒƒãƒ„ãƒ€ã‚¤ã‚¢ãƒªãƒ¼ äººç”Ÿã‚’å¤‰ãˆã‚‹ãƒãƒ¼ãƒˆè¡“](https://amzn.to/3wfwxrz)")
    expander.markdown("[è„³ã‚’é›ãˆã‚‹ã«ã¯é‹å‹•ã—ã‹ãªã„ï¼æœ€æ–°ç§‘å­¦ã§ã‚ã‹ã£ãŸè„³ç´°èƒã®å¢—ã‚„ã—æ–¹](https://amzn.to/3iS9Y95)")
    
    st.markdown("## æ˜ ç”»ã¨ã‹")
    st.markdown("[Filmarks](https://filmarks.com/users/uwasanoaitsu)", unsafe_allow_html=True)
    expander_movies = st.expander("å¥½ããªæ˜ ç”»10ä½œï¼ˆã‹ã£ã“ã„ã„ã®ãŒãŠå¥½ãï¼‰")
    expander_movies.markdown("[ã‚ªãƒ‡ãƒƒã‚»ã‚¤](https://filmarks.com/movies/59606?mark_id=124488725)")
    expander_movies.markdown("[ã‚¢ãƒ¡ã‚¤ã‚¸ãƒ³ã‚°ãƒ»ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ãƒãƒ³2](https://filmarks.com/movies/54983?mark_id=124488381)")
    expander_movies.markdown("[ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ãƒãƒ³ï¼šãƒãƒ¼ãƒ»ã‚¦ã‚§ã‚¤ãƒ»ãƒ›ãƒ¼ãƒ ](https://filmarks.com/movies/86717?mark_id=130674288)")
    expander_movies.markdown("[ã‚°ãƒ©ãƒ³ãƒ»ãƒˆãƒªãƒ](https://filmarks.com/movies/24424?mark_id=124487700)")
    expander_movies.markdown("[ãã£ã¨ã€ã†ã¾ãã„ã](https://filmarks.com/movies/53954?mark_id=124487979)")
    expander_movies.markdown("[LEON](https://filmarks.com/movies/33501?mark_id=124487607)")
    expander_movies.markdown("[æµ…è‰ã‚­ãƒƒãƒ‰](https://filmarks.com/movies/94105?mark_id=124197771)")
    expander_movies.markdown("[ã‚¨ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ»ã‚¸ãƒ§ãƒ–](https://filmarks.com/movies/82544?mark_id=125624553)")
    expander_movies.markdown("[ãƒãƒ¼ãƒ¬ã‚¹ã‚¯](https://filmarks.com/movies/15130?mark_id=124488582)")
    expander_movies.markdown("[è¨€ã®è‘‰ã®åº­](https://filmarks.com/movies/54374?mark_id=124489880)")
    
    
# ---Countries I talked---
st.markdown("## è‹±ä¼šè©±è¬›å¸«ã®å‡ºèº«å›½")
gdf = gpd.read_file('https://raw.githubusercontent.com/johan/world.geo.json/master/countries.geo.json')

c_df = pd.read_csv("countries.csv", header=0, names=["country", "code"])
c_df["from"] = "1"
c_df = c_df.groupby("code").max().reset_index().sort_values("from", ascending=False)

gdf_c = gdf.merge(c_df, left_on="id", right_on="code", how="left")
gdf_c = gdf_c.fillna(0)
gdf1 = gpd.GeoDataFrame(gdf_c)

centroid=gdf1.geometry.centroid
m = folium.Map(location=[centroid.y.mean(), centroid.x.mean()], zoom_start=1.5, tiles='OpenStreetMap')

folium.GeoJson(gdf1[['geometry', 'name', 'from']], 
               name = "Where My teachers are from",
               style_function = lambda x: {"weight":1, 'color':'grey','fillColor':'#bcbcbc' if x['properties']['from'] == 0 else '#C81D25', 'fillOpacity':0.8, 'colorOpacity': 0.1},
               highlight_function=lambda x: {'weight':3, 'color':'grey', 'fillOpacity':1},
               smooth_factor=2.0,
               tooltip=folium.features.GeoJsonTooltip(fields=['name'],
                                              aliases=['Country:'], 
                                              labels=True, 
                                              sticky=True,
                                             )
).add_to(m)

st_data = st_folium(m, width=1200, height=500)